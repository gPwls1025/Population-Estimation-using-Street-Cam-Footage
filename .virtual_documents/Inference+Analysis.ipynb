#@title Install dependencies
from IPython.display import clear_output, display, Image

clear_output()





import os
import subprocess
import pandas as pd
import re
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import networkx as nx

clear_output()


df = pd.read_csv("YOLO+RAM_merged.csv")
df.drop(df.columns[0], axis=1,inplace=True)


df.head()





all_tags = set()
for tags in df['RAM_Tags']:
    all_tags.update(tags.split(' | '))
all_tags = sorted(list(all_tags))

# Creating co-occurrence matrices
co_occurrence_overall = pd.DataFrame(index=all_tags, columns=all_tags).fillna(0)

# Function to update co-occurrence matrices
def update_co_occurrence(df, co_occurrence_matrix):
    for _, row in df.iterrows():
        tags = row['RAM_Tags'].split(' | ')
        for i in range(len(tags)):
            for j in range(i+1, len(tags)):
                co_occurrence_matrix.at[tags[i], tags[j]] += 1
                co_occurrence_matrix.at[tags[j], tags[i]] += 1


co_occurrence_overall_total = []

# Updating co-occurrence matrices and normalizing by location
for location, df_location in df.groupby('location'):
    co_occurrence_grouped = co_occurrence_overall.copy()
    update_co_occurrence(df_location, co_occurrence_grouped) # count occurrences
    co_occurrence_grouped /= df_location.shape[0] # normalize the counts for each loc
    co_occurrence_overall_total.append((location,co_occurrence_grouped))

# Average the matrices
co_occurrence_overall = sum(comat_loc[1] for comat_loc in co_occurrence_overall_total) / len(co_occurrence_overall_total)


# top N co-occuring pairs
def top_n_cooccur_pairs(df, location, top_n):
    pairs = df.stack()
    pairs = pairs[pairs.index.get_level_values(0) < pairs.index.get_level_values(1)]
    top_pairs = pairs.sort_values(ascending=False).head(top_n)
    print(f"Top Co-occurring Pairs in {location.capitalize()}:")
    print(top_pairs)

# Top N tags by overall co-occurrences
def top_n_common_item(df, location, top_n):
    tag_sums = df.sum(axis=1)
    top_n_tags = tag_sums.sort_values(ascending=False).head(top_n)
    print(f"\nTop Tags by Overall Co-occurrences in {location.capitalize()}:")
    print(top_n_tags)


co_occurrence_overall





top_n_cooccur_pairs(co_occurrence_overall_total[0][1], co_occurrence_overall_total[0][0], 10) 


top_n_common_item(co_occurrence_overall_total[0][1], co_occurrence_overall_total[0][0], 10) 





top_n_cooccur_pairs(co_occurrence_overall_total[1][1], co_occurrence_overall_total[1][0], 10) 


top_n_common_item(co_occurrence_overall_total[1][1], co_occurrence_overall_total[1][0], 10) 





top_n_cooccur_pairs(co_occurrence_overall_total[2][1], co_occurrence_overall_total[2][0], 10) 


top_n_common_item(co_occurrence_overall_total[2][1], co_occurrence_overall_total[2][0], 10) 


text = ' | '.join(df['RAM_Tags'])
words = text.split('|')
words = [word.strip().lower() for word in words]

# Count the occurrences of each word
word_counts = pd.Series(words).value_counts()

#Make a df for storage
word_counts_df = pd.DataFrame(word_counts)
word_counts_df.reset_index(inplace=True)
word_counts_df.columns = ['Tag','RAM_Count']


word_counts_df


word_counts_df_filtered = word_counts_df[~((word_counts_df['RAM_Count']>0.75*len(df)) | (word_counts_df['RAM_Count'] <= 4))]
word_counts_df_filtered


# Function to create a graph from the co-occurrence matrix
def create_graph_from_co_occurrence(co_occurrence_matrix, word_counts_df):
    G = nx.Graph()
    filtered_tags = set(word_counts_df['Tag'])  # Get only the tags present in word_counts_df_filtered
    for i in range(len(co_occurrence_matrix.index)):
        tag1 = co_occurrence_matrix.index[i]
        if tag1 in filtered_tags:
            G.add_node(tag1)
            for j in range(i + 1, len(co_occurrence_matrix.columns)):
                tag2 = co_occurrence_matrix.columns[j]
                if tag2 in filtered_tags:
                   def create_graph_from_co_occurrence(co_occurrence_matrix, word_counts_df):
    G = nx.Graph()
    filtered_tags = set(word_counts_df['Tag'])  # Get only the tags present in word_counts_df_filtered
    for i in range(len(co_occurrence_matrix.index)):
        tag1 = co_occurrence_matrix.index[i]
        if tag1 in filtered_tags:
            G.add_node(tag1)
            for j in range(i + 1, len(co_occurrence_matrix.columns)):
                tag2 = co_occurrence_matrix.columns[j]
                if tag2 in filtered_tags:
                    weight = co_occurrence_matrix.iloc[i, j]
                    if weight >= 3:  # Only add edge if co-occurrence count is 3 or more
                        G.add_edge(tag1, tag2, weight=weight)
    # Assigning node size based on word counts
    for node in G.nodes():
        word_count = word_counts_df[word_counts_df['Tag'] == node]['RAM_Count'].values
        if len(word_count) > 0:
            G.nodes[node]['size'] = word_count[0]  # Taking the word count from word_counts_df
    return G weight = co_occurrence_matrix.iloc[i, j]
                    if weight >= 3:  # Only add edge if co-occurrence count is 3 or more
                        G.add_edge(tag1, tag2, weight=weight)
    # Assigning node size based on word counts
    for node in G.nodes():
        word_count = word_counts_df[word_counts_df['Tag'] == node]['RAM_Count'].values
        if len(word_count) > 0:
            G.nodes[node]['size'] = word_count[0]  # Taking the word count from word_counts_df
    return G

# Creating a Plotly figure
def plot_network(graph, title):
    pos = nx.spring_layout(graph, seed=42)  # Layout for better visualization

    max_weight = max([graph.edges[edge]['weight'] for edge in graph.edges()]) if graph.edges() else 1

    edge_trace = []
    for edge in graph.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        weight = graph.edges[edge]['weight']
        edge_trace.append(go.Scatter(x=[x0, x1, None], y=[y0, y1, None], mode='lines', line=dict(width=0.04 * weight, color=f'rgb({int(128 * weight / max_weight)}, {int(128 * weight / max_weight)}, {int(128 * weight / max_weight)})')))  # Adjusting edge width and color

    node_trace = go.Scatter(x=[], y=[], mode='markers', text=[], marker=dict(size=[], color=[], colorscale='Viridis', opacity=0.7))
    for node in graph.nodes():
        x, y = pos[node]
        node_trace['x'] += (x,)
        node_trace['y'] += (y,)
        node_trace['marker']['size'] += (graph.nodes[node].get('size', 1) * 0.04,)  # Adjusting node size
        connected_nodes = list(graph.neighbors(node))
        top_connected_nodes = sorted(connected_nodes, key=lambda x: graph.edges[(node, x)]['weight'], reverse=True)[:20]  # Get top 20 most connected nodes
        top_connected_nodes_text = "<br>".join(top_connected_nodes) if top_connected_nodes else "None"
        #node_trace['text'] += (node,)
        node_trace['text'] += ([f'Node: {node}<br>Connections: {len(connected_nodes)}<br>Top Connected Nodes: {top_connected_nodes_text}'],)  # Adjusting node text
        node_trace['marker']['color'] += (graph.nodes[node].get('size', 1) * 10,)  # Adjusting node color

    fig = go.Figure(data=[*edge_trace, node_trace],
                    layout=go.Layout(title=title, showlegend=False, hovermode='closest',
                                     margin=dict(b=20, l=5, r=5, t=40),
                                     xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                                     yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))
                    )
    fig.show()

# Creating graphs from co-occurrence matrices
graph_overall = create_graph_from_co_occurrence(co_occurrence_overall, word_counts_df_filtered)

# Plotting networks
plot_network(graph_overall, "Network for Chase1")


total_nodes = graph_overall.number_of_nodes()
print("Total number of nodes in the graph:", total_nodes)





df['man'] = df['RAM_Tags'].str.contains(r'\bman\b|\bboy\b', case=False, regex=True).astype(int)
df['woman'] = df['RAM_Tags'].str.contains(r'\bwoman\b|\bgirl\b', case=False, regex=True).astype(int)
