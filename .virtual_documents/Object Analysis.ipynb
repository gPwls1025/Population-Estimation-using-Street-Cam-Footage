#@title Install dependencies
from IPython.display import clear_output, display, Image

clear_output()





import os
import subprocess
import pandas as pd
import re
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import networkx as nx
import plotly.express as px
import streamlit as st

clear_output()


df = pd.read_csv("data/YOLO+RAM_merged.csv")
df.drop(df.columns[0], axis=1,inplace=True)


df.head()





all_tags = set()
for tags in df['RAM_Tags']:
    all_tags.update(tags.split(' | '))
all_tags = sorted(list(all_tags))

# Creating co-occurrence matrices
co_occurrence_overall = pd.DataFrame(index=all_tags, columns=all_tags).fillna(0)

# Function to update co-occurrence matrices
def update_co_occurrence(df, co_occurrence_matrix):
    for _, row in df.iterrows():
        tags = row['RAM_Tags'].split(' | ')
        for i in range(len(tags)):
            for j in range(i+1, len(tags)):
                co_occurrence_matrix.at[tags[i], tags[j]] += 1
                co_occurrence_matrix.at[tags[j], tags[i]] += 1


co_occurrence_overall_total = []

# Updating co-occurrence matrices and normalizing by location
for location, df_location in df.groupby('location'):
    co_occurrence_grouped = co_occurrence_overall.copy()
    update_co_occurrence(df_location, co_occurrence_grouped) # Count occurrences

    # Normalize the counts for each loc
    co_occurrence_grouped /= df_location.shape[0] 
    co_occurrence_overall_total.append((location,co_occurrence_grouped))

    # Saving each location dataframe of the co-occurrence matrix
    co_occurrence_grouped.to_csv(f"data/{location}_cooccurrence.csv")
    
# Average the matrices
co_occurrence_overall = sum(comat_loc[1] for comat_loc in co_occurrence_overall_total) / len(co_occurrence_overall_total)

# Save the combined co-occurrence matrix
co_occurrence_overall.to_csv(f"data/total_cooccurrence.csv")


# Top N co-occuring pairs
def top_n_cooccur_pairs(df, location, top_n):
    
    pairs = df.stack().reset_index()
    pairs.columns = ['Term1', 'Term2', 'Co-occurrence']
    pairs = pairs[pairs['Term1'] < pairs['Term2']]
    top_pairs = pairs.sort_values(by='Co-occurrence', ascending=False).head(top_n)
    
    print(f"Top Co-occurring Pairs in {location.capitalize()}:")

    return top_pairs


# Top N tags by overall co-occurrences
def top_n_common_item(df, location, top_n):
    tag_sums = df.sum(axis=1)
    top_n_tags = tag_sums.sort_values(ascending=False).head(top_n)
    print(f"\nTop Tags by Overall Co-occurrences in {location.capitalize()}:")
    print(top_n_tags)    


person_associated_words = [
    'baby',
    'boy',
    'businessman',
    'child',
    'construction worker',
    'couple',
    'daughter',
    'girl',
    'man',
    'mother',
    'nun',
    'officer',
    'pedestrian',
    'person',
    'protester',
    'runner',
    'skater',
    'skateboarder',
    'student',
    'woman'
]





chase_df = pd.read_csv('data/chase_cooccurrence.csv', index_col=0)


top_n_cooccur_pairs(chase_df, 'chase', 30) 


top_n_common_item(co_occurrence_overall_total[0][1], co_occurrence_overall_total[0][0], 10) 


chase_df.loc['car', person_associated_words].sum()





top_n_cooccur_pairs(co_occurrence_overall_total[1][1], co_occurrence_overall_total[1][0], 10) 


top_n_common_item(co_occurrence_overall_total[1][1], co_occurrence_overall_total[1][0], 10) 


co_occurrence_overall_total[1][1].loc['car', person_associated_words].sum()


co_occurrence_overall_total[1][1].to_csv("data/dumbo_cooccurrence.csv")





top_n_cooccur_pairs(co_occurrence_overall_total[2][1], co_occurrence_overall_total[2][0], 10) 


top_n_common_item(co_occurrence_overall_total[2][1], co_occurrence_overall_total[2][0], 10) 


co_occurrence_overall_total[2][1].loc['car', person_associated_words].sum()








import dash
from dash import dcc, html, Input, Output
import pandas as pd
import plotly.graph_objects as go
from process import update_co_occurrence, create_filtered_word_counts_df, get_word_counts_and_co_occurrence
from plots import create_graph_from_co_occurrence, plot_network, get_tag_data_without_label, plot_tag_counts_by_location

# Load your data
file_path = 'data/'
df = pd.read_csv(file_path + 'YOLO+RAM_merged.csv')
df.drop(columns=['Unnamed: 0'], inplace=True)

word_counts_df_filtered, co_occurrence_overall, words_cps_1, words_cps_2, words_cps_3 = get_word_counts_and_co_occurrence(df)


word_counts_df_filtered



